
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="Up to this point, the tutorial clusters have managed all table primary keys and indexes in memory, while persisting table data to local GemFire XD disk store files. In this tutorial, you will create a ..."/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="copyright" content="(C) Copyright 2005"/><meta name="DC.rights.owner" content="(C) Copyright 2005"/><meta name="DC.Type" content="concept"/><meta name="DC.Title" content="Persist Tables to Hadoop"/><meta name="abstract" content="Up to this point, the tutorial clusters have managed all table primary keys and indexes in memory, while persisting table data to local GemFire XD disk store files. In this tutorial, you will create a table that persists data to HDFS log files."/><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="Up to this point, the tutorial clusters have managed all table primary keys and indexes in memory, while persisting table data to local GemFire XD disk store files. In this tutorial, you will create a table that persists data to HDFS log files."/><meta name="DC.Relation" scheme="URI" content="../tutorial_chapter_intro.html"/><meta name="DC.Format" content="XHTML"/><meta name="DC.Identifier" content="concept_55B8FBB016E54149B1BC06B857194235"/><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Persist Tables to Hadoop</title><meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="Content-Type" content="text/html; charset=utf-8"><!----></meta><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/pivotal.css"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" id="concept_55B8FBB016E54149B1BC06B857194235"><script xmlns="http://www.w3.org/1999/xhtml" src="//use.typekit.net/clb0qji.js" type="text/javascript"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  try {
				  Typekit.load();
			  } catch (e) {
			  }
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  document.domain = "pivotal.io";
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			WebFontConfig = {
			  google: { families: [ 'Source+Sans+Pro:300italic,400italic,300,400,600:latin' ] }
			};
			(function() {
			  var wf = document.createElement('script');
			  wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
				'://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
			  wf.type = 'text/javascript';
			  wf.async = 'true';
			  var s = document.getElementsByTagName('script')[0];
			  s.parentNode.insertBefore(wf, s);
			})();
		  </script>
<table class="nav"><tbody><tr><td colspan="2"><div id="permalink"><a href="#" title="Link to this page"/></div><div id="printlink"><a href="javascript:window.print();" title="Print this page"/></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../book_intro.html" title="Getting Started with GemFire XD provides step-by-step procedures for installing, configuring, and using GemFire XD. The guide also explains main concepts and provides tutorials to help you quickly begin using GemFire XD.">Getting Started with GemFire XD</a> / <a class="navheader_parent_path" href="../tutorial_chapter_intro.html" title="Learn to configure and use GemFire XD features such as table replication and partitioning, persisting data to local disk stores and HDFS, and dynamically resizing the cluster.">QuickStart Tutorials</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../tutorial_chapter_intro.html" title="Learn to configure and use GemFire XD features such as table replication and partitioning, persisting data to local disk stores and HDFS, and dynamically resizing the cluster."><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">QuickStart Tutorials</span></a></span>  </div></td></tr></tbody></table>
 
  <h1 class="title topictitle1">Persist Tables to Hadoop</h1>
 
   
  <div class="body conbody"><p class="shortdesc">Up to this point, the tutorial clusters have managed all table primary keys and indexes
		in memory, while persisting table data to local GemFire XD disk store files. In this
		tutorial, you will create a table that persists data to HDFS log files. </p>
 
	 <p class="p"><strong class="ph b">Prerequisites</strong>
	 </p>
 
	 <div class="note note"><span class="notetitle">Note:</span> This tutorial and the next tutorial require that you use GemFire XD with Pivotal HD
			Enterprise for Hadoop services. The simplest way to complete these tutorials is to
			download and run the Pivotal HD Single Node VM, available at <a class="xref" href="http://www.pivotal.io/big-data/pivotal-hd" target="_blank">http://www.pivotal.io/big-data/pivotal-hd</a>. The
			tutorial assumes that you perform the steps from within the downloaded virtual machine.
				<p class="p">If you are not using the virtual machine, ensure that you have followed the
				installation instructions to copy the necessary Pivotal HD library files to the
					<span class="ph filepath">/ext-lib</span> subdirectory of your GemFire XD directory, and
				that the user running your local GemFire XD members has permission to access HDFS
				nodes. See <a class="xref" href="install_intro.html#install-setup" title="You can install GemFire for production use from a downloaded RPM file (RHEL only) or from a downloaded ZIP file (Windows or RHEL). Pivotal also provides a Debian package and Homebrew packages for development with Ubuntu and Mac OSX. The following sections describe how to install the standalone GemFire XD product using a downloaded RPM file, ZIP file, Debian package, or Homebrew package.">Installing GemFire XD</a> and <a class="xref" href="../../disk_storage/persist-hdfs-topics.html#topic_v5l_3nn_ml" title="GemFire XD supports the Pivotal HD Enterprise Hadoop implementation for persisting table data to HDFS. If you have configured Pivotal HD with Kerberos for secure HDFS, then you must perform additional steps to ensure that each GemFire XD member can authenticate with Kerberos, and has permission to write table data to the HDFS store. The specific configuration requirements for secure HDFS differ depending on whether you installed GemFire XD as a component of Pivotal HD (using the Pivotal Command Center CLI) or you installed GemFire XD as a standalone product outside of Pivotal HD (using either the RPM or ZIP file distribution).">Configuration Requirements for Secure HDFS</a> for more
				information.</p>
</div>
 
	 <div class="p"><strong class="ph b">Procedure</strong> 
	 <ol class="ol" id="concept_55B8FBB016E54149B1BC06B857194235__ol_5E8DC3117C1A4E4BB9A43FED9B6613BE"> 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_7433E22F4A15479D8361D0DB620DE1AD">Start the virtual machine
		  and open a terminal window.
		</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_2499A5CCB9C448F2BC873DB4E57ACB83">Execute the following script to start the GemFire XD
					distributed system along with the required Pivotal HD services: <pre class="pre codeblock">$ <strong class="ph b">~/Desktop/start_gfxd.sh</strong></pre>

					<div class="note note"><span class="notetitle">Note:</span> It can take several minutes or more to start all services on the virtual
						machine, depending on the configuration of your host computer. </div>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_F36A2BAB83B24FD2813881B4FF718A1E">To ensure that you can access the Pivotal HD
					namenode, open a new terminal window and use the Hadoop filesystem browser to
					list the contents of the Pivotal HD filesystem: <pre class="pre codeblock">$ <strong class="ph b">hadoop fs -ls hdfs://pivhdsne:8020/</strong>
Found 7 items
drwxr-xr-x   - hdfs    hadoop          0 2014-03-10 18:39 hdfs://pivhdsne:8020/apps
drwxr-xr-x   - gpadmin hadoop          0 2014-03-10 18:44 hdfs://pivhdsne:8020/hawq_data
drwxr-xr-x   - hdfs    hadoop          0 2014-03-10 18:40 hdfs://pivhdsne:8020/hive
drwxr-xr-x   - mapred  hadoop          0 2014-03-10 18:38 hdfs://pivhdsne:8020/mapred
drwxrwxrwx   - hdfs    hadoop          0 2014-03-10 18:38 hdfs://pivhdsne:8020/tmp
drwxrwxrwx   - hdfs    hadoop          0 2014-03-10 18:45 hdfs://pivhdsne:8020/user
drwxr-xr-x   - hdfs    hadoop          0 2014-03-10 18:39 hdfs://pivhdsne:8020/yarn</pre>

					<p class="p">(If you are not using the Pivotal HD Single Node VM, substitute the correct
						URL for your HDFS filesystem browser.) Keep this second terminal window open
						in order to view results in HDFS. </p>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_2563D2E000404307ADC3130787EAAFEE">Change to the GemFire XD 
		  <span class="ph filepath">quickstart</span> directory and connect to the GemFire XD
		  distributed system as a client using 
		  <samp class="ph codeph">gfxd</samp>:
		  <pre class="pre codeblock">$ <strong class="ph b">cd /usr/lib/gphd/gfxd/quickstart</strong>
$ <strong class="ph b">gfxd</strong>
gfxd version 1.4.0
gfxd&gt; <strong class="ph b">connect client 'localhost:1527';</strong></pre>

		</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_5688F9906985487DA4DD05AA8AC74A63">In the <samp class="ph codeph">gfxd</samp> session terminal, create
					an HDFS store to use for persisting table data to Hadoop: <pre class="pre codeblock">gfxd&gt; <strong class="ph b">create hdfsstore flightstore namenode 'hdfs://pivhdsne:8020' homedir '/flights';</strong>
0 rows inserted/updated/deleted</pre>

					<div class="note note"><span class="notetitle">Note:</span> The CREATE HDFSSTORE command has many additional properties to configure
						the queues used to persist table data to HDFS and the compaction behavior
						for read/write HDFS files. This file does not specify most of these options,
						so default values are used. See <a class="xref" href="../../reference/language_ref/ref-create-hdfs-store.html#reference_2CEECA47241D4FBAA2C92D598BC50200" title="Creates a connection to a Hadoop name node in order to persist one or more tables to HDFS. Each connection defines the HDFS NameNode and directory to use for persisting data, as well as GemFire XD-specific options to configure the queue used to persist table events, enable persistence for the connection, compact the HDFS operational logs, and so forth.">CREATE HDFSSTORE</a> for more information about
						available options and defaults. </div>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_F8EB764F2A9346FA8DB52AF13AEE33F7">GemFire XD places the new HDFS store directory in the
						<span class="ph filepath">/flights</span> subdirectory in HDFS. You can verify this
					using the <samp class="ph codeph">hadoop</samp> command from the terminal prompt: <pre class="pre codeblock">$ <strong class="ph b">hadoop fs -ls hdfs://pivhdsne:8020/flights</strong>
Found 2 items
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:35 hdfs://pivhdsne:8020/flights/.hopmeta
-rw-r--r--   3 gpadmin hadoop          8 2014-03-29 05:35 hdfs://pivhdsne:8020/flights/cleanUpInterval</pre>

					<p class="p">Because no tables are using the HDFS store yet, there's only a single
						directory available for storing metadata. The metadata at this point
						consists only of the DDL command that used to create the HDFS store itself.
						As you create tables that use the HDFS store, DDL for those tables is added
						to the metadata directory, and is used by MapReduce jobs to understand the
						schema of the table data stored in HDFS log files. </p>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_BE1188B0269249C3B8E507A80A363C8E">The table that we will
		  configure to use the HDFS store is the FLIGHTAVAILABILITY table. First use the 
		  <samp class="ph codeph">gfxd</samp> terminal window drop the current version of this
		  table from the schema if it already exists:
		  <pre class="pre codeblock">gfxd&gt; <strong class="ph b">drop table if exists app.flightavailability;</strong>
0 rows inserted/updated/deleted
</pre>

		</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_0F2B4AED9F7443A78FFCA303CEFD307E">Create a new version of the table, using both the
					EVICTION BY CRITERIA clause and the HDFSSTORE clause, as follows: <pre class="pre codeblock">gfxd&gt; <strong class="ph b">CREATE TABLE FLIGHTAVAILABILITY
    (
       FLIGHT_ID VARCHAR(6) NOT NULL ,
       SEGMENT_NUMBER INTEGER NOT NULL ,
       FLIGHT_DATE DATE NOT NULL ,
       ECONOMY_SEATS_TAKEN INTEGER DEFAULT 0,
       BUSINESS_SEATS_TAKEN INTEGER DEFAULT 0,
       FIRSTCLASS_SEATS_TAKEN INTEGER DEFAULT 0,
       PRIMARY KEY (FLIGHT_ID, SEGMENT_NUMBER, FLIGHT_DATE)
    )
    PARTITION BY PRIMARY KEY
    eviction by criteria (firstclass_seats_taken=0)
    evict incoming
    persistent
    hdfsstore (flightstore);</strong>
0 rows inserted/updated/deleted
</pre>

					<p class="p">In this create table command, the HDFSSTORE clause specifies the HDFS store
						that GemFire XD will use to perist data for the table. The EVICTION BY
						CRITERIA clause defines the in-memory, operational data set for the table.
						(As an alternative, you can configure the table to evict matching data
						periodically, using the <a class="xref" href="../../reference/language_ref/ref-create-table-clauses.html#topic_hyr_bs4_5k" title="Use the EVICTION BY CRITERIA clause to define the working (in-memory) data set for HDFS read/write or HDFS write-only tables. If you use the EVICTION BY CRITERIA clause, you must also include the HDFSSTORE clause to enable HDFS persistence.">EVICTION FREQUENCY</a> clause.) Each time a new row is inserted or
						updated with the column value firstclass_seats_taken=0, GemFire XD evicts
						that row from memory. The row remains available in HDFS for processing
						historical data using MapReduce jobs or using HAWQ. You'll see the results
						of this eviction behavior in the next few steps. </p>
<div class="note note"><span class="notetitle">Note:</span> The PERSISTENT
						clause in this statement persists only the in-memory data for the table,
						using GemFire XD operational log files. This ensures that the operational
						data set remains available through server restarts. See <a class="xref" href="tutorial_persist.html#concept_55B8FBB016E54149B1BC06B857194235" title="By default, a GemFire XD distributed system persists only the data dictionary for the tables and indexes you create. These persistence files are stored in the datadictionary subdirectory of each locator and data store that joins the distributed system. Table data, however, is not persisted by default; if you shut down all GemFire XD members, the tables are empty on the next startup. In this tutorial you will persist table data to GemFire XD disk store files.">Persist Tables to Disk</a>
						for a tutorial showing basic GemFire XD persistence to local disk
							stores.<p class="p">If you do not include the PERSISTENT clause then no in-memory
							data for the table is restored. Although that data still resides in HDFS
							log files, GemFire XD does not provide a mechanism for restoring the
							data to heap or off-heap memory.</p>
</div>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_5BFF712A2B6E47F8AEA728E5CBF0B8F9">Load data into the table by
		  running the following SQL scripts, which are installed to the 
		  <span class="ph filepath">quickstart</span> subdirectory:
		  <pre class="pre codeblock">gfxd&gt; <strong class="ph b">run 'loadFLIGHTAVAILABILITY1.sql';</strong>
gfxd&gt; <strong class="ph b">run 'loadFLIGHTAVAILABILITY2.sql';</strong></pre>

		</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_EFAD893036AB493486C2717E7A7F654F">In the Linux terminal window, re-run the hadoop
					command to list the contents of the HDFS store: <pre class="pre codeblock">$ <strong class="ph b">hadoop fs -ls hdfs://pivhdsne:8020/flights</strong>
Found 3 items
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:37 hdfs://pivhdsne:8020/flights/.hopmeta
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY
-rw-r--r--   3 gpadmin hadoop          8 2014-03-29 05:35 hdfs://pivhdsne:8020/flights/cleanUpInterval</pre>

					<div class="p">GemFire XD created a new directory, APP_FLIGHTAVAILABILITY for the table
						data. Individual log files for the persisted data are stored in
						subdirectories of the table directory:
						<pre class="pre codeblock">$ <strong class="ph b">hadoop fs -ls hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY</strong>
Found 112 items
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/0
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/1
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/10
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/100
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/101
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/102
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/103
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/104
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/105
drwxr-xr-x   - gpadmin hadoop          0 2014-03-29 05:38 hdfs://pivhdsne:8020/flights/APP_FLIGHTAVAILABILITY/106
[...]</pre>

					</div>

					<p class="p">A subdirectory is created for each bucket of the partitioned table. See <a class="xref" href="../../disk_storage/persist-hdfs-topics.html#topic_368CE64D716E48078795FAD470A5C372" title="When you configure a table for HDFS persistence, GemFire XD places all data to be persisted to HDFS in an asynchronous queue. A single HDFS queue is created for each set of colocated tables that use the queue. A configurable number of dispatcher threads periodically write batches of updates from the queue to HDFS operational log files. The behavior of the HDFS queue and the number and format of HDFS log files differ depending on whether you configure a table for HDFS write-only or HDFS read/write persistence.">How GemFire XD Manages HDFS Data</a> for more information abou the different types of HDFS log files that
						GemFire XD creates.</p>
<p class="p">After GemFire XD creates the log files, they
						remain available in HDFS for processing with MapReduce jobs or HAWQ until
						you remove the files. For the type of read/write table that you created in
						this tutorial, GemFire XD also performs automatic compaction to combine
						multiple log files into a smaller number of larger log files. See <a class="xref" href="../../disk_storage/persist-hdfs-topics.html#topic_368CE64D716E48078795FAD470A5C372__section_1EFE6875389847B9824B7E59CF9F904F">Compaction for HDFS Log Files</a> for more information. </p>

				</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_0742858EAA61446E9103C85399C3BDB0">In the <samp class="ph codeph">gfxd</samp> session, execute the
					following queries on the new table: <pre class="pre codeblock">gfxd&gt; <strong class="ph b">select count(*) from flightavailability;</strong>
1          
-----------
400        

1 row selected
gfxd&gt; <strong class="ph b">select count(*) from flightavailability where firstclass_seats_taken=0;</strong>
1          
-----------
0          

1 row selected</pre>

					<div class="p">By default, queries against HDFS tables only access the in-memory,
						operational data for the table. As you can see from the second query, there
						are no in-memory rows where the values of the firstclass_seats_taken column
						are equal to 0. This is because, in the CREATE TABLE statement, you
						specified that all tables that meet this criteria should be evicted from
						memory. In order to query the full table data (both in-memory, operational
						data and data persisted to HDFS), you must include the <strong class="ph b">queryHDFS</strong> hint
						in your query: <pre class="pre codeblock">gfxd&gt; <strong class="ph b">select count(*) from flightavailability --GEMFIREXD-PROPERTIES queryHDFS=true \n ;</strong>
1          
-----------
518        

1 row selected
gfxd&gt; <strong class="ph b">select count(*) from flightavailability --GEMFIREXD-PROPERTIES queryHDFS=true \n where firstclass_seats_taken=0;</strong>
1          
-----------
118        

1 row selected
</pre>

						<div class="note note"><span class="notetitle">Note:</span> Because the <strong class="ph b">queryHDFS</strong> hint is specified in a SQL comment, it
							must appear at the end of a line. In order to continue the SQL command
							after the comment, include the \n characters (or a return) after
							defining the hint and before terminating the SQL command. See <a class="xref" href="../../manage_guide/Topics/optimizer-hints.html#concept_A93B4A631E7E42C39093021C2DAB1C74" title="You can override the default behavior of the GemFire XD query optimizer by including a -- GEMFIREXD-PROPERTIES clause and a property definition in a SQL statement. The clause and property definition both appear within the context of a SQL comment (beginning with two dashes &#34;--&#34;).">Overriding Optimizer Choices</a> for more information. </div>

					</div>
<p class="p">With the queryHDFS hint specified, the queries now operate against the
						full HDFS data and return the complete data set, including rows that were
						evicted to HDFS. </p>

				</li>

				<li class="li">Using <samp class="ph codeph">count(*)</samp> with <samp class="ph codeph">queryHDFS=true</samp> is fine for
					the small table we just created. But executing this statement on a large table
					could take a very long time, because GemFire XD has to iterate over all of the
					table's HDFS data. For this reason, GemFire XD provides a convenience function,
						<a class="xref noPageCitation" href="../../reference/language_ref/functions/count_estimate.html#rrefsqlj66113" title="An aggregate function that returns the estimated total number of rows in an HDFS read/write table (rows in operational memory as well as rows persisted to HDFS).">COUNT_ESTIMATE</a>, to quickly return an estimate of the total
					number of rows for an HDFS read/write
					table:<pre class="pre codeblock">gfxd&gt; <strong class="ph b">select count(*) as operational, count_estimate('app.flightavailability') as estimate from flightavailability;</strong>
OPERATIONAL|ESTIMATE            
--------------------------------
400        |513                 

1 row selected
</pre>
</li>
 
		<li class="li" id="concept_55B8FBB016E54149B1BC06B857194235__li_13CA1163DA56436B8E89E7A0861DE24F">Exit the 
		  <samp class="ph codeph">gfxd</samp> session: 
		  <pre class="pre codeblock">gfxd&gt; <strong class="ph b">exit;</strong></pre>
 
		</li>
 
	 </ol>
 
	 </div>
 
  </div>
 
<div class="related-links"/>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../tutorial_chapter_intro.html" title="Learn to configure and use GemFire XD features such as table replication and partitioning, persisting data to local disk stores and HDFS, and dynamically resizing the cluster."><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">QuickStart Tutorials</span></a></span>  </div><div>
<div class="container">
  <footer class="site-footer-links">
    <div class="copyright">
      <a href="http://docs.pivotal.io" target="_blank">Pivotal Documentation</a>
      Â© 2014 <a href="http://www.pivotal.io/" target="_blank">Pivotal Software</a>, Inc. All Rights Reserved.
  </div>
  <div class="support">
    Need help? <a href="http://support.pivotal.io" target="_blank">Visit Support</a>
   </div>
  </footer>
</div><!--end of container-->
</div>
</body>
</html>