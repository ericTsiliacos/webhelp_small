
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="When you persist the data for a GemFire XD table to HDFS, the HDFS log files enable you to analyze the table data outside of the GemFire XD distributed system, using Hadoop tools such as MapReduce or ..."/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="copyright" content="(C) Copyright 2005"/><meta name="DC.rights.owner" content="(C) Copyright 2005"/><meta name="DC.Type" content="concept"/><meta name="DC.Title" content="MapReduce Example"/><meta name="abstract" content="When you persist the data for a GemFire XD table to HDFS, the HDFS log files enable you to analyze the table data outside of the GemFire XD distributed system, using Hadoop tools such as MapReduce or Pivotal HAWQ. GemFire XD includes a MapReduce example that helps you generate HDFS table data and then access the data using a Hadoop MapReduce job."/><meta xmlns="http://www.w3.org/1999/xhtml" name="description" content="When you persist the data for a GemFire XD table to HDFS, the HDFS log files enable you to analyze the table data outside of the GemFire XD distributed system, using Hadoop tools such as MapReduce or Pivotal HAWQ. GemFire XD includes a MapReduce example that helps you generate HDFS table data and then access the data using a Hadoop MapReduce job."/><meta name="DC.Relation" scheme="URI" content="../book_intro.html"/><meta name="DC.Format" content="XHTML"/><meta name="DC.Identifier" content="concept_a44_y2f_4l"/><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>MapReduce Example</title><meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="Content-Type" content="text/html; charset=utf-8"><!----></meta><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><link xmlns="http://www.w3.org/1999/xhtml" rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/pivotal.css"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" id="concept_a44_y2f_4l"><script xmlns="http://www.w3.org/1999/xhtml" src="//use.typekit.net/clb0qji.js" type="text/javascript"/><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  try {
				  Typekit.load();
			  } catch (e) {
			  }
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			  document.domain = "pivotal.io";
		  </script><script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
			WebFontConfig = {
			  google: { families: [ 'Source+Sans+Pro:300italic,400italic,300,400,600:latin' ] }
			};
			(function() {
			  var wf = document.createElement('script');
			  wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
				'://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
			  wf.type = 'text/javascript';
			  wf.async = 'true';
			  var s = document.getElementsByTagName('script')[0];
			  s.parentNode.insertBefore(wf, s);
			})();
		  </script>
<table class="nav"><tbody><tr><td colspan="2"><div id="permalink"><a href="#" title="Link to this page"/></div><div id="printlink"><a href="javascript:window.print();" title="Print this page"/></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../book_intro.html" title="Getting Started with GemFire XD provides step-by-step procedures for installing, configuring, and using GemFire XD. The guide also explains main concepts and provides tutorials to help you quickly begin using GemFire XD.">Getting Started with GemFire XD</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../book_intro.html" title="Getting Started with GemFire XD provides step-by-step procedures for installing, configuring, and using GemFire XD. The guide also explains main concepts and provides tutorials to help you quickly begin using GemFire XD."><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Getting Started with GemFire XD</span></a></span>  </div></td></tr></tbody></table>

 <h1 class="title topictitle1">MapReduce Example</h1>

 
 <div class="body conbody"><p class="shortdesc">When you persist the data for a GemFire XD table to HDFS, the HDFS log files enable you
    to analyze the table data outside of the GemFire XD distributed system, using Hadoop tools such
    as MapReduce or Pivotal HAWQ. GemFire XD includes a MapReduce example that helps you generate
    HDFS table data and then access the data using a Hadoop MapReduce job.</p>

    <div class="note note"><span class="notetitle">Note:</span> The MapReduce example is a standalone application with support scripts to create GemFire
      XD system and populate data. It does not use or build upon the distributed system created in
      the <a class="xref" href="../tutorial_chapter_intro.html#concept_A14BF60B65314B97BA19EE6C81620CB3" title="Learn to configure and use GemFire XD features such as table replication and partitioning, persisting data to local disk stores and HDFS, and dynamically resizing the cluster.">QuickStart Tutorials</a>. </div>

  <p class="p"><strong class="ph b">Prerequisites</strong></p>

  <p class="p">The MapReduce example requires that you use GemFire XD with Pivotal HD Enterprise for Hadoop
      services. The simplest way to complete this tutorial is to download and run the Pivotal HD
      Single Node VM, available at <a class="xref" href="http://www.pivotal.io/big-data/pivotal-hd" target="_blank">http://www.pivotal.io/big-data/pivotal-hd</a>. After starting
      the virtual machine, double-click the <span class="ph filepath">start_gfxd.sh</span> script on the desktop
      to start all Pivotal HD services. </p>

    <p class="p">You should be familiar with the Hadoop MapReduce API in order to fully understand the GemFire
      XD MapReduce example. See the Hadoop <a class="xref" href="http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html" target="_blank">MapReduce Tutorial</a> for general information about MapReduce.</p>

  <p class="p">The MapReduce example application is installed with GemFire XD in the
        <span class="ph filepath">examples/mapreduce</span> subdirectory of the product installation directory.
      The sample application uses a set of scripts to start GemFire XD locators and servers, create
      the required schema, and execute the compiled MapReduce jobs. In addition to helping you
      modify and run the necessary scripts, this tutorial calls out excerpts of the MapReduce code
      to help you understand how GemFire XD extends the MapReduce API to help you easily work with
      GemFire XD table data. If you want more information about compiling the example code from
      source, see the <span class="ph filepath">/examples/mapreduce/readme.txt</span> file installed in the
      GemFire XD directory.</p>

    <p class="p"><strong class="ph b">Procedure</strong></p>

  <ol class="ol" id="concept_a44_y2f_4l__ul_tbr_1ff_4l">
   <li class="li">Shut down any GemFire XD distributed system that may still be running on your system.  The
    MapReduce example automatically starts a new distributed system for generating HDFS data, and
    existing members could cause conflicts when running on the same machine. To shut down the system
    that was used in the previous
    tutorials:<pre class="pre codeblock">$ <strong class="ph b">cd ~</strong>
$ <strong class="ph b">gfxd shut-down-all -locators=localhost[10101]</strong>
$ <strong class="ph b">gfxd locator stop -dir=locator</strong></pre>
</li>

      <li class="li">If you have not already started the Pivotal HD services in the virtual machine, do so
          now:<pre class="pre codeblock">$ <strong class="ph b">~/Desktop/start_all.sh
</strong>Starting services
Starting cluster
[...]</pre>
<div class="note note"><span class="notetitle">Note:</span> It
          can take several minutes or more to start all services on the virtual machine, depending
          on the configuration of your host computer. </div>
</li>

   <li class="li">Move to the MapReduce example <span class="ph filepath">/scripts</span>
        directory:<pre class="pre codeblock">$ <strong class="ph b">cd /usr/lib/gphd/gfxd/examples/mapreduce/scripts</strong></pre>
</li>

   <li class="li">Open the <span class="ph filepath">mr_driver.sh</span> file with a text editor. Look for the following
    lines in the
     file:<pre class="pre codeblock">GFXD=/usr/bin/gfxd
export BIND_ADDRESS=HOSTNAME

GFXD_HOME=/usr/lib/gphd/gfxd
</pre>
<p class="p">If
     you did not install GemFire XD using the RPM installation, edit the GFXD and GFXD_HOME values
     to point to the location of the gfxd utility and the GemFire XD installation utility,
     respectively.  If you installed using the RPM installer, then you do not need to modify these
     lines.</p>
<div class="p">In all cases, change the HOSTNAME entry to the host name of the GemFire XD
     machine. For example, if you installed GemFire XD into the Pivotal HD Single Node VM, the lines
     should look
     like:<pre class="pre codeblock">GFXD=/usr/bin/gfxd
export BIND_ADDRESS=<strong class="ph b">pivhdsne</strong>

GFXD_HOME=/usr/lib/gphd/gfxd
</pre>
</div>
<p class="p">Save
     the file after you have made the required changes.</p>
</li>

   <li class="li">Open the <span class="ph filepath">create_hdfs_schema.sql</span> file in a text editor, and locate the
    LOCATOR and HOSTNAME references in bold
     below:<pre class="pre codeblock">AUTOCOMMIT OFF;

CONNECT CLIENT '<strong class="ph b">LOCATOR</strong>:1527'

DROP TABLE IF EXISTS BUSY_AIRPORT;
DROP TABLE IF EXISTS FLIGHTS_HISTORY;
DROP TABLE IF EXISTS MAPS;
DROP TABLE IF EXISTS FLIGHTAVAILABILITY;
DROP TABLE IF EXISTS FLIGHTS;
DROP TABLE IF EXISTS CITIES;
DROP TABLE IF EXISTS COUNTRIES;
DROP TABLE IF EXISTS AIRLINES;

-- DROP TRIGGER IF EXISTS TRIG1;
-- DROP TRIGGER IF EXISTS TRIG2;

DROP HDFSSTORE IF EXISTS airlines;

CREATE HDFSSTORE airlines
    NAMENODE 'hdfs://<strong class="ph b">HOSTNAME</strong>:8020'
    HOMEDIR '/tmp/gfxd'
    BatchTimeInterval 5000 milliseconds;
</pre>
<div class="p">Change
     these references to the hostname that will run the GemFire XD locator member and the hostname
     that runs the Pivotal HD name node. If you installed GemFire XD in the Pivotal HD Single Node
     VM, use "pivhdsne" for both of these values, as
     in:<pre class="pre codeblock">AUTOCOMMIT OFF;

CONNECT CLIENT '<strong class="ph b">pivhdsne</strong>:1527'

DROP TABLE IF EXISTS BUSY_AIRPORT;
DROP TABLE IF EXISTS FLIGHTS_HISTORY;
DROP TABLE IF EXISTS MAPS;
DROP TABLE IF EXISTS FLIGHTAVAILABILITY;
DROP TABLE IF EXISTS FLIGHTS;
DROP TABLE IF EXISTS CITIES;
DROP TABLE IF EXISTS COUNTRIES;
DROP TABLE IF EXISTS AIRLINES;

-- DROP TRIGGER IF EXISTS TRIG1;
-- DROP TRIGGER IF EXISTS TRIG2;

DROP HDFSSTORE IF EXISTS airlines;

CREATE HDFSSTORE airlines
    NAMENODE 'hdfs://<strong class="ph b">pivhdsne</strong>:8020'
    HOMEDIR '/tmp/gfxd'
    BatchTimeInterval 5000 milliseconds;
</pre>
</div>
<p class="p">Save
     the file after you have made the required changes.</p>
</li>

   <li class="li">Execute the mr_driver.sh script with the clear argument to remove any temporary files that
    may have been created by previously running the MapReduce
     examples:<pre class="pre codeblock">$ <strong class="ph b">./mr_driver.sh clear</strong>
The specified working directory (server1) contains no status file
The specified working directory (locator1) contains no status file
rm: `/output': No such file or directory
rm: `/output_int': No such file or directory</pre>
<p class="p">If
     you receive messages similar to the above, it simply means that none of the example's temporary
     directories need to be removed.</p>
</li>

   <li class="li">Start the GemFire XD distributed
          system:<pre class="pre codeblock">$ <strong class="ph b">./mr_driver.sh start</strong>
Starting GemFireXD Locator using peer discovery on: 0.0.0.0[19992]
Starting network server for GemFireXD Locator at address pivhdsne/127.0.0.1[1527]
Logs generated in /usr/lib/gphd/Pivotal_GemFireXD_10/examples/mapreduce/scripts/locator1/gfxdlocator.log
GemFireXD Locator pid: 35717 status: running
Starting GemFireXD Server using locators for peer discovery: localhost[19992]
Starting network server for GemFireXD Server at address pivhdsne/127.0.0.1[1528]
Logs generated in /usr/lib/gphd/Pivotal_GemFireXD_10/examples/mapreduce/scripts/server1/gfxdserver.log
GemFireXD Server pid: 35824 status: running
  Distributed system now has 2 members.
  Other members: 10.0.1.22(35717:locator)&lt;v0&gt;:31512</pre>
<p class="p">The
          script creates local directories a locator and data store member
            (<span class="ph filepath">./locator1</span> and <span class="ph filepath">./server1</span>), and starts both
          members. The distributed system will be used for loading data and, in the final MapReduce
          job, to write data back into a GemFire XD table.</p>
</li>

   <li class="li">The next script that you execute will create the database schema and load tables with data.
        Before you execute the script, examine the key tables and data involved. In the
          <span class="ph filepath">create_hdfs_schema.sql</span> file, you can see the following HDFS store and
        table are
          created:<pre class="pre codeblock">CREATE HDFSSTORE airlines
    NAMENODE 'hdfs://pivhdsne:8020'
    HOMEDIR '/tmp/gfxd'
    BatchTimeInterval 5000 milliseconds;
...
CREATE TABLE FLIGHTS_HISTORY
   (
      FLIGHT_ID CHAR(6),
      SEGMENT_NUMBER INTEGER,
      ORIG_AIRPORT CHAR(3),
      DEPART_TIME TIME,
      DEST_AIRPORT CHAR(3),
      ARRIVE_TIME TIME,
      MEAL CHAR(1),
      FLYING_TIME DOUBLE PRECISION,
      MILES INTEGER,
      AIRCRAFT VARCHAR(6), 
      STATUS VARCHAR (20)
   )
   PARTITION BY COLUMN (FLIGHT_ID, SEGMENT_NUMBER)
   BUCKETS 5
   HDFSSTORE (airlines);
</pre>
<p class="p">The
          MapReduce job that you run later will be accessing the FLIGHTS_HISTORY HDFS log files,
          stored in HDFS under the /tmp/gfxd directory. Notice that the BUCKETS 5 clause limits the
          total number of buckets in the table for running the example. Each BUCKET will receive a
          dedicated HDFS subdirectory and collection of log files, so the number of HDFS bucket
          directories will be limited to 5.</p>
<p class="p">After creating the full schema, the script
          executes the <span class="ph filepath">fh-10000.sql</span> file to load 10,000 rows into
          FLIGHTS_HISTORY.</p>
</li>

   <li class="li">Execute the following command to create the schema and load
     data:<pre class="pre codeblock">$ <strong class="ph b">./mr_driver.sh load</strong></pre>
<p class="p">The data loading step may take
     several minutes, depending on the speed of your system.</p>
</li>

   <li class="li">The example class that you will run executes two separate MapReduce job. The first job uses
        the GemFire XD RowInputFormat implementation to identify the table name and HFDS log files
        to use as input to the Mapper implementation. Look at the following configuration code from
        the run method in the
          <span class="ph filepath">/usr/lib/gphd/gfxd/examples/mapreduce/src/main/java/demo/gfxd/mr2/TopBusyAirportGemfirexd.java</span>
          file:<pre class="pre codeblock">    conf.set(<strong class="ph b">RowInputFormat.HOME_DIR, hdfsHomeDir</strong>);
    conf.set(<strong class="ph b">RowInputFormat.INPUT_TABLE, tableName</strong>);
    conf.setBoolean(<strong class="ph b">RowInputFormat.CHECKPOINT_MODE, false</strong>);

    Job job = Job.getInstance(conf, "Busy Airport Count");
    job.setJarByClass(TopBusyAirportGemfirexd.class);

    job.setInputFormatClass(<strong class="ph b">RowInputFormat.class</strong>);

    // configure mapper and reducer
    job.setMapperClass(SampleMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);

    // configure output
    TextOutputFormat.setOutputPath(job, intermediateOutputPath);
    job.setOutputFormatClass(TextOutputFormat.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);</pre>
<p class="p">For
          the first MapReduce job, the example sets the GemFire XD RowInputFormat.class
          implementation as the InputFormat class, and configures it with the highlighted HDFS store
          directory and table name. The <samp class="ph codeph">RowInputFormat.CHECKPOINT_MODE</samp> indicates
          that the compacted log files, which represent a snapshot of the table's current values,
          are not used as input. Instead, the job uses the full set of raw HDFS log files that
          include all operations against the table. The output of the first MapReduce job is
          configured to write text to an intermediate file.</p>
<div class="p">The map method in SampleMapper
          class performs the work for the first MapReduce job, which involves tallying the
          ORIG_AIRPORT and DEST_AIRPORT in a temporary
          file:<pre class="pre codeblock">  public static class SampleMapper extends Mapper&lt;Object, Row, Text, IntWritable&gt; {

    private final static IntWritable countOne = new IntWritable(1);
    private final Text reusableText = new Text();

    @Override
    public void map(<strong class="ph b">Object key</strong>, <strong class="ph b">Row row</strong>, Context context)
        throws IOException, InterruptedException {

      String origAirport;
      String destAirport;

      try {
        <strong class="ph b">ResultSet rs = row.getRowAsResultSet();</strong>
        origAirport = rs.getString("ORIG_AIRPORT");
        destAirport = rs.getString("DEST_AIRPORT");
        reusableText.set(origAirport);
        context.write(reusableText, countOne);
        reusableText.set(destAirport);
        context.write(reusableText, countOne);
      } catch (SQLException e) {
        e.printStackTrace();
      }
    }</pre>
</div>
<p class="p">In
          the highlighted sections, you can see that the RowInputFormat implementation delivers
          table records using key and row objects. The key object itself contains no relevant table
          data; it is included only to conform to the standard Hadoop interface. The row object
          contains all relevant information for the table record. In the SampleMapper class, the row
          is cast to a result set, and tallies for the ORIG_AIRPORT and DEST_AIRPORT are written to
          intermediate files in the operating system.</p>
</li>

   <li class="li">In the second part of the run method, a second MapReduce job is configured as
          follows:<pre class="pre codeblock">      String gemfirexdUrl = topConf.get("gemfirexd.url", "jdbc:gemfirexd://localhost:1527");
      topConf.set(<strong class="ph b">RowOutputFormat.OUTPUT_URL, gemfirexdUrl</strong>);
      topConf.set(<strong class="ph b">RowOutputFormat.OUTPUT_TABLE, "APP.BUSY_AIRPORT"</strong>);
...
      topJob.setOutputFormatClass(<strong class="ph b">RowOutputFormat.class</strong>);
      topJob.setOutputKeyClass(Key.class);
      topJob.setOutputValueClass(<strong class="ph b">BusyAirportModel.class</strong>);

</pre>
<div class="p">Instead
          of writing results to a file, the second MapReduce job, uses the GemFire XD
          RowOutputFormat implementation to write results to a table, connecting to the running
          GemFire XD system with the provided URL. BusyAirportModel.class defines the schema of this
          table using the JDBC API. The reduce method of the second MapReduce job simply determines
          the busiest airport, and writes the value to the output table:
          <pre class="pre codeblock">  public static class TopBusyAirportReducer extends Reducer&lt;Text, StringIntPair, Key, BusyAirportModel&gt; {

    @Override
    public void reduce(Text token, Iterable&lt;StringIntPair&gt; values,
        Context context) throws IOException, InterruptedException {
      String topAirport = null;
      int max = 0;

      for (StringIntPair v : values) {
        if (v.getSecond() &gt; max) {
          max = v.getSecond();
          topAirport = v.getFirst();
        }
      }
      <strong class="ph b">BusyAirportModel busy = new BusyAirportModel(topAirport, max);
      context.write(new Key(), busy);</strong>
    }
  }</pre>
</div>
<p class="p">Again,
          the key object is provided only to conform to the Hadoop API; the key contains no relevant
          table data.</p>
</li>

   <li class="li">To execute both MapReduce jobs, execute the
          command:<pre class="pre codeblock">$ <strong class="ph b">./mr_driver.sh runMR</strong></pre>
<div class="p">At the completion of the process, you should see the
          output:<pre class="pre codeblock">[fine 2014/03/29 06:07:52.481 CST &lt;Distributed system shutdown hook&gt; tid=0xb] &lt;Hoplog:HdfsStore:StoreForDDLFetching7770299402355&gt; Closing file system: StoreForDDLFetching7770299402355
Heap
 def new generation   total 76672K, used 30134K [0x00000000bc600000, 0x00000000c1930000, 0x00000000c1930000)
  eden space 68160K,  44% used [0x00000000bc600000, 0x00000000be36dab0, 0x00000000c0890000)
  from space 8512K,   0% used [0x00000000c0890000, 0x00000000c0890000, 0x00000000c10e0000)
  to   space 8512K,   0% used [0x00000000c10e0000, 0x00000000c10e0000, 0x00000000c1930000)
 concurrent mark-sweep generation total 893088K, used 536508K [0x00000000c1930000, 0x00000000f8158000, 0x00000000fae00000)
 concurrent-mark-sweep perm gen total 83968K, used 58350K [0x00000000fae00000, 0x0000000100000000, 0x0000000100000000)

real	0m24.624s
user	0m8.747s
sys	0m2.066s
Found 2 items
-rw-r--r--   3 gpadmin hadoop          0 2014-03-29 06:07 /output_int/_SUCCESS
-rw-r--r--   3 gpadmin hadoop        691 2014-03-29 06:07 /output_int/part-r-00000
gfxd&gt; select * from busy_airport;
AIR&amp;|FLIGHTS    |STAMP                     
-------------------------------------------
JFK |860        |2014-03-29 06:07:51.921   

1 row selected
gfxd&gt;</pre>
</div>
<p class="p">By
          processing the full history events in the FLIGHTS_HISTORY table, the MapReduce example
          determined which airport had the most arrivals and departures combined.</p>
</li>

   <li class="li">To view the intermediate output from the first MapReduce
        job:<pre class="pre codeblock">$ <strong class="ph b">hdfs dfs -cat hdfs://pivhdsne:8020/output_int/part-r-00000</strong>
...
PHL	122
PHX	155
PRG	208
REY	199
SAN	120
SAT	230
SCL	244
SEA	421
SEL	157
SFO	490
SHA	175
SIN	331
SJU	109
SLC	193
STL	123
SVO	409
SYD	402
THR	176
TPE	219
WAW	170
YUL	187
YYZ	185</pre>
</li>

   <li class="li">To view the table output of the second MapReduce
        job:<pre class="pre codeblock">$ <strong class="ph b">gfxd</strong>
gfxd version 1.4.0
gfxd&gt; <strong class="ph b">connect client 'localhost:1527';</strong>
gfxd&gt; <strong class="ph b">select * from busy_airport;</strong>
AIRPORT|FLIGHTS    |STAMP                     
----------------------------------------------
JFK    |860        |2014-03-29 06:07:51.921   

1 row selected</pre>
</li>

   <li class="li">To stop and remove GemFire XD distributed system, and remove all temporary directories,
        execute the
        command:<pre class="pre codeblock">$ <strong class="ph b">./mr_driver.sh clear</strong>
The GemFireXD Server has stopped.
The GemFireXD Locator has stopped.
rm: `/output': No such file or directory
14/03/29 06:10:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 86400000 minutes, Emptier interval = 0 minutes.
Moved: 'hdfs://pivhdsne.localdomain:8020/output_int' to trash at: hdfs://pivhdsne.localdomain:8020/user/gpadmin/.Trash/Current</pre>
</li>

  </ol>

 </div>

<div class="related-links"/>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../book_intro.html" title="Getting Started with GemFire XD provides step-by-step procedures for installing, configuring, and using GemFire XD. The guide also explains main concepts and provides tutorials to help you quickly begin using GemFire XD."><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Getting Started with GemFire XD</span></a></span>  </div><div>
<div class="container">
  <footer class="site-footer-links">
    <div class="copyright">
      <a href="http://docs.pivotal.io" target="_blank">Pivotal Documentation</a>
      Â© 2014 <a href="http://www.pivotal.io/" target="_blank">Pivotal Software</a>, Inc. All Rights Reserved.
  </div>
  <div class="support">
    Need help? <a href="http://support.pivotal.io" target="_blank">Visit Support</a>
   </div>
  </footer>
</div><!--end of container-->
</div>
</body>
</html>